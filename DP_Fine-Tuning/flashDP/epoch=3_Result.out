Requirement already satisfied: pip in ./pytorch_example_env/lib/python3.11/site-packages (25.2)
Requirement already satisfied: numpy in ./pytorch_example_env/lib/python3.11/site-packages (2.3.2)
Requirement already satisfied: torch in ./pytorch_example_env/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: filelock in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in ./pytorch_example_env/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in ./pytorch_example_env/lib/python3.11/site-packages (from triton==3.4.0->torch) (65.5.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./pytorch_example_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./pytorch_example_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: transformers in ./pytorch_example_env/lib/python3.11/site-packages (4.55.4)
Requirement already satisfied: filelock in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (3.19.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (2.3.2)
Requirement already satisfied: packaging>=20.0 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (2025.7.34)
Requirement already satisfied: requests in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<0.22,>=0.21 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (0.21.4)
Requirement already satisfied: safetensors>=0.4.3 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in ./pytorch_example_env/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: fsspec>=2023.5.0 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: charset_normalizer<4,>=2 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)
Requirement already satisfied: datasets in ./pytorch_example_env/lib/python3.11/site-packages (4.0.0)
Requirement already satisfied: filelock in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (3.19.1)
Requirement already satisfied: numpy>=1.17 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (2.3.2)
Requirement already satisfied: pyarrow>=15.0.0 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (21.0.0)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (2.3.2)
Requirement already satisfied: requests>=2.32.2 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (2.32.5)
Requirement already satisfied: tqdm>=4.66.3 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (4.67.1)
Requirement already satisfied: xxhash in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (3.5.0)
Requirement already satisfied: multiprocess<0.70.17 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (0.70.16)
Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in ./pytorch_example_env/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)
Requirement already satisfied: huggingface-hub>=0.24.0 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (0.34.4)
Requirement already satisfied: packaging in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (25.0)
Requirement already satisfied: pyyaml>=5.1 in ./pytorch_example_env/lib/python3.11/site-packages (from datasets) (6.0.2)
Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./pytorch_example_env/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)
Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./pytorch_example_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)
Requirement already satisfied: aiosignal>=1.4.0 in ./pytorch_example_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)
Requirement already satisfied: attrs>=17.3.0 in ./pytorch_example_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)
Requirement already satisfied: frozenlist>=1.1.1 in ./pytorch_example_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)
Requirement already satisfied: multidict<7.0,>=4.5 in ./pytorch_example_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)
Requirement already satisfied: propcache>=0.2.0 in ./pytorch_example_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)
Requirement already satisfied: yarl<2.0,>=1.17.0 in ./pytorch_example_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)
Requirement already satisfied: idna>=2.0 in ./pytorch_example_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)
Requirement already satisfied: typing-extensions>=4.2 in ./pytorch_example_env/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.15.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)
Requirement already satisfied: charset_normalizer<4,>=2 in ./pytorch_example_env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.3)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./pytorch_example_env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in ./pytorch_example_env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.8.3)
Requirement already satisfied: python-dateutil>=2.8.2 in ./pytorch_example_env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./pytorch_example_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in ./pytorch_example_env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: six>=1.5 in ./pytorch_example_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)
Requirement already satisfied: tqdm in ./pytorch_example_env/lib/python3.11/site-packages (4.67.1)
Requirement already satisfied: scikit-learn in ./pytorch_example_env/lib/python3.11/site-packages (1.7.1)
Requirement already satisfied: numpy>=1.22.0 in ./pytorch_example_env/lib/python3.11/site-packages (from scikit-learn) (2.3.2)
Requirement already satisfied: scipy>=1.8.0 in ./pytorch_example_env/lib/python3.11/site-packages (from scikit-learn) (1.16.1)
Requirement already satisfied: joblib>=1.2.0 in ./pytorch_example_env/lib/python3.11/site-packages (from scikit-learn) (1.5.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in ./pytorch_example_env/lib/python3.11/site-packages (from scikit-learn) (3.6.0)
Requirement already satisfied: sentencepiece in ./pytorch_example_env/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: accelerate in ./pytorch_example_env/lib/python3.11/site-packages (1.10.1)
Requirement already satisfied: numpy<3.0.0,>=1.17 in ./pytorch_example_env/lib/python3.11/site-packages (from accelerate) (2.3.2)
Requirement already satisfied: packaging>=20.0 in ./pytorch_example_env/lib/python3.11/site-packages (from accelerate) (25.0)
Requirement already satisfied: psutil in ./pytorch_example_env/lib/python3.11/site-packages (from accelerate) (7.0.0)
Requirement already satisfied: pyyaml in ./pytorch_example_env/lib/python3.11/site-packages (from accelerate) (6.0.2)
Requirement already satisfied: torch>=2.0.0 in ./pytorch_example_env/lib/python3.11/site-packages (from accelerate) (2.8.0)
Requirement already satisfied: huggingface_hub>=0.21.0 in ./pytorch_example_env/lib/python3.11/site-packages (from accelerate) (0.34.4)
Requirement already satisfied: safetensors>=0.4.3 in ./pytorch_example_env/lib/python3.11/site-packages (from accelerate) (0.6.2)
Requirement already satisfied: filelock in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)
Requirement already satisfied: fsspec>=2023.5.0 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)
Requirement already satisfied: requests in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)
Requirement already satisfied: tqdm>=4.42.1 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)
Requirement already satisfied: typing-extensions>=3.7.4.3 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./pytorch_example_env/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.9)
Requirement already satisfied: sympy>=1.13.3 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)
Requirement already satisfied: networkx in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5)
Requirement already satisfied: jinja2 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in ./pytorch_example_env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in ./pytorch_example_env/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (65.5.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./pytorch_example_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./pytorch_example_env/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in ./pytorch_example_env/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)
Wrapping the model with FlashDP...
Warning: Module type 'LayerNorm' specified in target_modules is not used in the model.
Layers Wrapped: model.layers.0.mlp, model.layers.18.self_attn.q_proj, model.layers.16.mlp.down_proj, model.layers.19.mlp.up_proj, model.layers.1.mlp.down_proj, model.layers.13.mlp.act_fn, model.layers.14.mlp.act_fn, model.layers.0.self_attn.k_proj, model.layers.15.post_attention_layernorm, model.layers.5.self_attn.k_proj, model.layers.19.self_attn.q_proj, model.layers.21.mlp.up_proj, model.layers.18.mlp.act_fn, model.layers.7.mlp.act_fn, model.layers.3.mlp.up_proj, model.layers.7.input_layernorm, model.layers.26.self_attn.k_proj, model.layers.22.mlp.up_proj, model.layers.18.self_attn, model.layers.6.mlp.down_proj, model.layers.22.self_attn.v_proj, model.layers.5.mlp.gate_proj, model.layers.16.input_layernorm, model.layers.0.mlp.gate_proj, model.layers.31.mlp.act_fn, model.layers.24.mlp.gate_proj, model.layers.3, model.layers.3.mlp.gate_proj, model.layers.26.post_attention_layernorm, model.layers.19.self_attn.k_proj, model.layers.27.self_attn.v_proj, model.layers.11.post_attention_layernorm, model.layers.24.self_attn, model.layers.25.input_layernorm, model.layers.25.self_attn.q_proj, model.layers.24.mlp.act_fn, model.layers.5.self_attn.o_proj, model.layers.3.input_layernorm, model.layers.9.mlp.up_proj, model.layers.27.self_attn, model.layers.4.mlp, model.layers.20.self_attn.q_proj, model.layers.1.mlp.up_proj, model.layers.12, model.layers.23.post_attention_layernorm, model.layers.3.mlp, model.layers.28.mlp.up_proj, model.layers.12.mlp.up_proj, model.layers.21.self_attn.k_proj, model.layers.26.self_attn.o_proj, model.layers.18, model.layers.27.mlp.gate_proj, model.layers.14.self_attn, model.layers.27.mlp.down_proj, model.layers.9.mlp.gate_proj, model.layers.1.self_attn, model.layers.29.self_attn, model.layers.22, model.layers.3.self_attn.q_proj, model.layers.24.input_layernorm, model.layers.27.self_attn.o_proj, model.layers.16, model.layers.19.mlp.act_fn, model.layers.31.mlp, model.layers.30.input_layernorm, model.layers.22.mlp, model.layers.23.self_attn.q_proj, model.layers.24, model.layers.30.mlp.down_proj, model.layers.14.input_layernorm, model.layers.28, model.layers.15.self_attn, model.layers.17.self_attn, model.layers.26.input_layernorm, model.layers.10.mlp.gate_proj, model.layers.30.self_attn.v_proj, model.layers.16.self_attn, model.layers.21.self_attn.o_proj, model.layers.12.self_attn.k_proj, model.layers.26.mlp.up_proj, model.layers.12.mlp.gate_proj, model.layers.10.mlp.up_proj, model.layers.10.mlp.act_fn, model.layers.6.mlp.up_proj, model.layers.19.post_attention_layernorm, model.layers.30.self_attn.o_proj, model.layers.1.self_attn.v_proj, model.layers.30.self_attn.q_proj, model.layers.7.post_attention_layernorm, model.layers.29.mlp.gate_proj, model.layers.21.mlp, model.layers.19.mlp, model.layers.14.self_attn.o_proj, model.layers.2.post_attention_layernorm, model.layers.9.mlp, model.layers.25.self_attn.o_proj, model.layers.21.input_layernorm, model.layers.22.self_attn.q_proj, model.layers.29.self_attn.o_proj, model.layers.19.self_attn.v_proj, model.layers.22.self_attn, model.layers.20.self_attn.v_proj, model.layers.20.mlp.down_proj, model.layers.19, model.layers.18.self_attn.v_proj, model.layers.5.self_attn, model.layers.3.mlp.down_proj, model.layers.16.mlp.act_fn, model.layers.28.mlp, model.layers.21.mlp.down_proj, model.layers.9, model.layers.18.mlp.gate_proj, model.layers.20.self_attn, model.layers.11.mlp.up_proj, model.layers.23.self_attn.o_proj, model.layers.24.self_attn.v_proj, model.layers.3.self_attn.o_proj, model.layers.8.mlp.up_proj, model.layers.21.mlp.gate_proj, model.layers.30.mlp.act_fn, model.layers.6.self_attn.o_proj, model.layers.2, model.layers.23.mlp.up_proj, model.layers.26.mlp.down_proj, model.layers.14.mlp.down_proj, model.layers.11.mlp.gate_proj, model.layers.1.self_attn.o_proj, model.layers.17.mlp.act_fn, model.layers.10.mlp.down_proj, model.layers.5, model.layers.15.mlp.gate_proj, model.layers.29.mlp, model.layers.22.post_attention_layernorm, model.layers.13.self_attn, model.layers.2.mlp.down_proj, model.layers.1.input_layernorm, model.layers.23.input_layernorm, model.layers.28.mlp.down_proj, model.layers.15.self_attn.q_proj, model.layers.23.self_attn, model.layers.24.post_attention_layernorm, model.layers.10.input_layernorm, model.layers.27.input_layernorm, model.layers.28.mlp.act_fn, model.layers.2.mlp.gate_proj, model.layers.22.input_layernorm, model.layers.8.self_attn.q_proj, model.layers.6.mlp.gate_proj, model.layers.4.mlp.gate_proj, model.layers.2.mlp.act_fn, model.layers.6.self_attn.q_proj, model.layers.18.mlp.down_proj, model.layers.30.post_attention_layernorm, model.layers.6.mlp.act_fn, model.layers.29.self_attn.k_proj, model.layers.23, model.layers.20, model.layers.16.post_attention_layernorm, model.layers.21, model.layers.29.post_attention_layernorm, model.layers.13.self_attn.q_proj, model.layers.26.self_attn.q_proj, model.layers.0.input_layernorm, model.layers.15, lm_head, model.layers.31.mlp.up_proj, model.layers.16.self_attn.k_proj, model.layers.2.self_attn.o_proj, model.layers.14, model.layers.12.self_attn, model.layers.30, model.layers.0, model.layers.11.self_attn.v_proj, model.layers.4.self_attn, model.layers.31.self_attn, model.layers.10.post_attention_layernorm, model.layers.13.self_attn.v_proj, model.layers.26, model.layers.22.mlp.gate_proj, model.layers.15.mlp.up_proj, model.layers.25.self_attn.k_proj, model.layers.11.self_attn.k_proj, model.layers.30.mlp, model.layers.12.self_attn.q_proj, model.layers.13.post_attention_layernorm, model.layers.3.post_attention_layernorm, model.layers.28.self_attn, model.layers.25.self_attn.v_proj, model.layers.4.self_attn.o_proj, model.layers.11.input_layernorm, model.layers.7, model.layers.10.self_attn, model.layers.1.self_attn.k_proj, model.layers.31.self_attn.k_proj, model.layers.31.self_attn.v_proj, model.layers.1.self_attn.q_proj, model.layers.25.mlp.up_proj, model.layers.20.mlp, model.layers.10.self_attn.v_proj, model.layers.7.mlp, model.layers.31, model.layers.26.mlp.act_fn, model.layers.16.mlp.up_proj, model.layers.21.self_attn.q_proj, model.layers.9.input_layernorm, model.layers.11.self_attn.q_proj, model.layers.14.mlp, model.layers.3.self_attn, model.layers.27, model.layers.15.mlp.down_proj, model.layers.22.mlp.act_fn, model.layers.29.input_layernorm, model.layers.31.post_attention_layernorm, model.layers.1.post_attention_layernorm, model.layers.10.self_attn.k_proj, model.layers.8.self_attn, model.layers.11.self_attn, model.layers.11.mlp.down_proj, model.layers.17.self_attn.k_proj, model.layers.10.mlp, model.layers.23.self_attn.v_proj, model.layers.21.self_attn.v_proj, model.layers.24.mlp.down_proj, model, model.layers.3.mlp.act_fn, model.layers.27.mlp, model.layers.24.mlp.up_proj, model.layers.6.self_attn.v_proj, model.layers.4.self_attn.v_proj, model.layers.17.post_attention_layernorm, model.layers.7.self_attn.o_proj, model.layers.18.mlp.up_proj, model.layers.12.mlp, model.layers.6.input_layernorm, model.layers.12.post_attention_layernorm, model.layers.15.self_attn.v_proj, model.layers.0.self_attn, model.layers.7.self_attn, model.layers.0.self_attn.v_proj, model.layers.15.input_layernorm, model.layers.30.self_attn.k_proj, model.rotary_emb, model.layers.5.self_attn.v_proj, model.layers.25, model.layers.5.input_layernorm, model.layers.28.post_attention_layernorm, model.norm, model.layers.9.mlp.down_proj, model.layers.13.mlp.down_proj, model.layers.20.mlp.up_proj, model.layers.7.self_attn.k_proj, model.layers.8.mlp.down_proj, model.layers.20.mlp.gate_proj, model.layers.0.self_attn.q_proj, model.layers.10.self_attn.o_proj, model.layers.15.self_attn.k_proj, model.layers.5.mlp.act_fn, model.layers.7.mlp.gate_proj, model.layers.17.self_attn.o_proj, model.layers.4.self_attn.q_proj, model.layers.21.self_attn, model.layers.29.self_attn.q_proj, model.layers.5.mlp, model.layers.9.self_attn.q_proj, model.layers.20.self_attn.o_proj, model.layers.24.self_attn.q_proj, model.layers.17.mlp.down_proj, model.layers.15.mlp, model.layers.27.mlp.up_proj, model.layers.0.mlp.act_fn, model.layers.9.mlp.act_fn, model.layers.4.post_attention_layernorm, model.layers.19.self_attn.o_proj, model.layers.7.mlp.up_proj, model.layers.23.mlp, model.layers.13.mlp.gate_proj, model.layers.25.mlp, model.layers.14.mlp.up_proj, model.layers.1.mlp.act_fn, model.layers.15.self_attn.o_proj, model.layers.13.input_layernorm, model.layers.19.mlp.gate_proj, model.layers.23.self_attn.k_proj, model.layers.11.self_attn.o_proj, model.layers.1.mlp, model.layers.17.self_attn.q_proj, model.layers.12.self_attn.v_proj, model.layers.12.input_layernorm, model.layers.1, model.layers.19.input_layernorm, model.layers.4.input_layernorm, model.layers.25.mlp.down_proj, model.layers.14.self_attn.k_proj, model.layers.9.post_attention_layernorm, model.layers.0.mlp.down_proj, model.layers.17.input_layernorm, model.layers.11.mlp.act_fn, model.layers.13.self_attn.k_proj, model.layers.31.mlp.down_proj, model.layers.8.input_layernorm, model.layers.2.mlp.up_proj, model.layers.8.mlp, model.layers.18.mlp, model.layers.3.self_attn.k_proj, model.layers.28.self_attn.q_proj, model.layers.13, model.layers.18.post_attention_layernorm, model.layers.28.input_layernorm, model.layers.29.mlp.up_proj, model.layers.26.mlp, model.layers.28.self_attn.v_proj, model.layers, model.layers.22.mlp.down_proj, model.layers.29.mlp.down_proj, model.layers.4, model.layers.31.input_layernorm, model.layers.9.self_attn.o_proj, model.layers.24.mlp, model.layers.27.self_attn.q_proj, model.layers.13.mlp.up_proj, model.layers.1.mlp.gate_proj, model.layers.13.self_attn.o_proj, model.layers.31.self_attn.q_proj, model.layers.2.self_attn.k_proj, model.layers.18.self_attn.k_proj, model.layers.16.mlp, model.layers.30.mlp.up_proj, model.layers.12.mlp.act_fn, model.layers.25.mlp.act_fn, model.layers.31.mlp.gate_proj, model.layers.30.self_attn, model.layers.4.self_attn.k_proj, model.layers.7.self_attn.q_proj, model.layers.6.post_attention_layernorm, model.layers.28.self_attn.o_proj, model.layers.17.self_attn.v_proj, model.layers.5.mlp.down_proj, model.layers.2.mlp, model.layers.22.self_attn.o_proj, model.layers.7.mlp.down_proj, model.layers.18.self_attn.o_proj, model.layers.2.self_attn, model.layers.19.mlp.down_proj, model.layers.13.mlp, model.layers.3.self_attn.v_proj, model.layers.23.mlp.act_fn, model.embed_tokens, model.layers.5.post_attention_layernorm, model.layers.19.self_attn, model.layers.17.mlp, model.layers.25.self_attn, model.layers.29.self_attn.v_proj, model.layers.24.self_attn.o_proj, model.layers.31.self_attn.o_proj, model.layers.9.self_attn, model.layers.5.mlp.up_proj, model.layers.16.self_attn.q_proj, model.layers.0.post_attention_layernorm, model.layers.29.mlp.act_fn, model.layers.14.self_attn.q_proj, model.layers.30.mlp.gate_proj, model.layers.14.mlp.gate_proj, model.layers.2.input_layernorm, model.layers.28.self_attn.k_proj, model.layers.20.mlp.act_fn, model.layers.12.mlp.down_proj, model.layers.17, model.layers.29, model.layers.0.self_attn.o_proj, model.layers.17.mlp.gate_proj, model.layers.27.post_attention_layernorm, model.layers.16.mlp.gate_proj, model.layers.9.self_attn.k_proj, model.layers.18.input_layernorm, model.layers.20.post_attention_layernorm, model.layers.4.mlp.up_proj, model.layers.23.mlp.gate_proj, model.layers.6.mlp, model.layers.26.self_attn.v_proj, model.layers.8.mlp.gate_proj, model.layers.2.self_attn.v_proj, model.layers.8.post_attention_layernorm, model.layers.16.self_attn.o_proj, model.layers.4.mlp.down_proj, model.layers.5.self_attn.q_proj, model.layers.27.mlp.act_fn, model.layers.10, model.layers.17.mlp.up_proj, model.layers.9.self_attn.v_proj, model.layers.28.mlp.gate_proj, model.layers.8.self_attn.o_proj, model.layers.24.self_attn.k_proj, model.layers.22.self_attn.k_proj, model.layers.8.self_attn.k_proj, model.layers.26.self_attn, model.layers.7.self_attn.v_proj, model.layers.20.self_attn.k_proj, model.layers.25.post_attention_layernorm, model.layers.10.self_attn.q_proj, model.layers.0.mlp.up_proj, model.layers.21.mlp.act_fn, model.layers.15.mlp.act_fn, model.layers.6, model.layers.12.self_attn.o_proj, model.layers.14.post_attention_layernorm, model.layers.2.self_attn.q_proj, model.layers.4.mlp.act_fn, model.layers.11.mlp, model.layers.16.self_attn.v_proj, model.layers.14.self_attn.v_proj, model.layers.26.mlp.gate_proj, model.layers.6.self_attn.k_proj, model.layers.21.post_attention_layernorm, model.layers.27.self_attn.k_proj, model.layers.6.self_attn, model.layers.25.mlp.gate_proj, model.layers.11, model.layers.20.input_layernorm, model.layers.23.mlp.down_proj, model.layers.8, model.layers.8.self_attn.v_proj, model.layers.8.mlp.act_fn
No layers Skipped.
Model wrapped with FlashDP.
FlashDP requires compilation for the first few iterations, which may take a while. Skipping the first few iterations if you want to compare the performance.
Epoch 1, Loss: 8.9229
Epoch 2, Loss: 7.5072
Epoch 3, Loss: 6.8309
DP Training completed with noise_multiplier=1.0, C=1.0, epochs=3, batch_size=4
Validation Loss: 1.2892
Validation Exact Match Accuracy: 0.4000
Q: Which NFL team represented the AFC at Super Bowl 50?
True: denver broncos
Pred: denver broncos

Q: Which NFL team represented the NFC at Super Bowl 50?
True: carolina panthers
Pred: carolina panthers

Q: Where did Super Bowl 50 take place?
True: santa clara, california
Pred: santa clara, california

Wrapping the model with FlashDP...
Warning: Module type 'LayerNorm' specified in target_modules is not used in the model.
Layers Wrapped: model.layers.0.mlp, model.layers.18.self_attn.q_proj, model.layers.16.mlp.down_proj, model.layers.19.mlp.up_proj, model.layers.1.mlp.down_proj, model.layers.13.mlp.act_fn, model.layers.14.mlp.act_fn, model.layers.0.self_attn.k_proj, model.layers.15.post_attention_layernorm, model.layers.5.self_attn.k_proj, model.layers.19.self_attn.q_proj, model.layers.21.mlp.up_proj, model.layers.18.mlp.act_fn, model.layers.7.mlp.act_fn, model.layers.3.mlp.up_proj, model.layers.7.input_layernorm, model.layers.26.self_attn.k_proj, model.layers.22.mlp.up_proj, model.layers.18.self_attn, model.layers.6.mlp.down_proj, model.layers.22.self_attn.v_proj, model.layers.5.mlp.gate_proj, model.layers.16.input_layernorm, model.layers.0.mlp.gate_proj, model.layers.31.mlp.act_fn, model.layers.24.mlp.gate_proj, model.layers.3, model.layers.3.mlp.gate_proj, model.layers.26.post_attention_layernorm, model.layers.19.self_attn.k_proj, model.layers.27.self_attn.v_proj, model.layers.11.post_attention_layernorm, model.layers.24.self_attn, model.layers.25.input_layernorm, model.layers.25.self_attn.q_proj, model.layers.24.mlp.act_fn, model.layers.5.self_attn.o_proj, model.layers.3.input_layernorm, model.layers.9.mlp.up_proj, model.layers.27.self_attn, model.layers.4.mlp, model.layers.20.self_attn.q_proj, model.layers.1.mlp.up_proj, model.layers.12, model.layers.23.post_attention_layernorm, model.layers.3.mlp, model.layers.28.mlp.up_proj, model.layers.12.mlp.up_proj, model.layers.21.self_attn.k_proj, model.layers.26.self_attn.o_proj, model.layers.18, model.layers.27.mlp.gate_proj, model.layers.14.self_attn, model.layers.27.mlp.down_proj, model.layers.9.mlp.gate_proj, model.layers.1.self_attn, model.layers.29.self_attn, model.layers.22, model.layers.3.self_attn.q_proj, model.layers.24.input_layernorm, model.layers.27.self_attn.o_proj, model.layers.16, model.layers.19.mlp.act_fn, model.layers.31.mlp, model.layers.30.input_layernorm, model.layers.22.mlp, model.layers.23.self_attn.q_proj, model.layers.24, model.layers.30.mlp.down_proj, model.layers.14.input_layernorm, model.layers.28, model.layers.15.self_attn, model.layers.17.self_attn, model.layers.26.input_layernorm, model.layers.10.mlp.gate_proj, model.layers.30.self_attn.v_proj, model.layers.16.self_attn, model.layers.21.self_attn.o_proj, model.layers.12.self_attn.k_proj, model.layers.26.mlp.up_proj, model.layers.12.mlp.gate_proj, model.layers.10.mlp.up_proj, model.layers.10.mlp.act_fn, model.layers.6.mlp.up_proj, model.layers.19.post_attention_layernorm, model.layers.30.self_attn.o_proj, model.layers.1.self_attn.v_proj, model.layers.30.self_attn.q_proj, model.layers.7.post_attention_layernorm, model.layers.29.mlp.gate_proj, model.layers.21.mlp, model.layers.19.mlp, model.layers.14.self_attn.o_proj, model.layers.2.post_attention_layernorm, model.layers.9.mlp, model.layers.25.self_attn.o_proj, model.layers.21.input_layernorm, model.layers.22.self_attn.q_proj, model.layers.29.self_attn.o_proj, model.layers.19.self_attn.v_proj, model.layers.22.self_attn, model.layers.20.self_attn.v_proj, model.layers.20.mlp.down_proj, model.layers.19, model.layers.18.self_attn.v_proj, model.layers.5.self_attn, model.layers.3.mlp.down_proj, model.layers.16.mlp.act_fn, model.layers.28.mlp, model.layers.21.mlp.down_proj, model.layers.9, model.layers.18.mlp.gate_proj, model.layers.20.self_attn, model.layers.11.mlp.up_proj, model.layers.23.self_attn.o_proj, model.layers.24.self_attn.v_proj, model.layers.3.self_attn.o_proj, model.layers.8.mlp.up_proj, model.layers.21.mlp.gate_proj, model.layers.30.mlp.act_fn, model.layers.6.self_attn.o_proj, model.layers.2, model.layers.23.mlp.up_proj, model.layers.26.mlp.down_proj, model.layers.14.mlp.down_proj, model.layers.11.mlp.gate_proj, model.layers.1.self_attn.o_proj, model.layers.17.mlp.act_fn, model.layers.10.mlp.down_proj, model.layers.5, model.layers.15.mlp.gate_proj, model.layers.29.mlp, model.layers.22.post_attention_layernorm, model.layers.13.self_attn, model.layers.2.mlp.down_proj, model.layers.1.input_layernorm, model.layers.23.input_layernorm, model.layers.28.mlp.down_proj, model.layers.15.self_attn.q_proj, model.layers.23.self_attn, model.layers.24.post_attention_layernorm, model.layers.10.input_layernorm, model.layers.27.input_layernorm, model.layers.28.mlp.act_fn, model.layers.2.mlp.gate_proj, model.layers.22.input_layernorm, model.layers.8.self_attn.q_proj, model.layers.6.mlp.gate_proj, model.layers.4.mlp.gate_proj, model.layers.2.mlp.act_fn, model.layers.6.self_attn.q_proj, model.layers.18.mlp.down_proj, model.layers.30.post_attention_layernorm, model.layers.6.mlp.act_fn, model.layers.29.self_attn.k_proj, model.layers.23, model.layers.20, model.layers.16.post_attention_layernorm, model.layers.21, model.layers.29.post_attention_layernorm, model.layers.13.self_attn.q_proj, model.layers.26.self_attn.q_proj, model.layers.0.input_layernorm, model.layers.15, lm_head, model.layers.31.mlp.up_proj, model.layers.16.self_attn.k_proj, model.layers.2.self_attn.o_proj, model.layers.14, model.layers.12.self_attn, model.layers.30, model.layers.0, model.layers.11.self_attn.v_proj, model.layers.4.self_attn, model.layers.31.self_attn, model.layers.10.post_attention_layernorm, model.layers.13.self_attn.v_proj, model.layers.26, model.layers.22.mlp.gate_proj, model.layers.15.mlp.up_proj, model.layers.25.self_attn.k_proj, model.layers.11.self_attn.k_proj, model.layers.30.mlp, model.layers.12.self_attn.q_proj, model.layers.13.post_attention_layernorm, model.layers.3.post_attention_layernorm, model.layers.28.self_attn, model.layers.25.self_attn.v_proj, model.layers.4.self_attn.o_proj, model.layers.11.input_layernorm, model.layers.7, model.layers.10.self_attn, model.layers.1.self_attn.k_proj, model.layers.31.self_attn.k_proj, model.layers.31.self_attn.v_proj, model.layers.1.self_attn.q_proj, model.layers.25.mlp.up_proj, model.layers.20.mlp, model.layers.10.self_attn.v_proj, model.layers.7.mlp, model.layers.31, model.layers.26.mlp.act_fn, model.layers.16.mlp.up_proj, model.layers.21.self_attn.q_proj, model.layers.9.input_layernorm, model.layers.11.self_attn.q_proj, model.layers.14.mlp, model.layers.3.self_attn, model.layers.27, model.layers.15.mlp.down_proj, model.layers.22.mlp.act_fn, model.layers.29.input_layernorm, model.layers.31.post_attention_layernorm, model.layers.1.post_attention_layernorm, model.layers.10.self_attn.k_proj, model.layers.8.self_attn, model.layers.11.self_attn, model.layers.11.mlp.down_proj, model.layers.17.self_attn.k_proj, model.layers.10.mlp, model.layers.23.self_attn.v_proj, model.layers.21.self_attn.v_proj, model.layers.24.mlp.down_proj, model, model.layers.3.mlp.act_fn, model.layers.27.mlp, model.layers.24.mlp.up_proj, model.layers.6.self_attn.v_proj, model.layers.4.self_attn.v_proj, model.layers.17.post_attention_layernorm, model.layers.7.self_attn.o_proj, model.layers.18.mlp.up_proj, model.layers.12.mlp, model.layers.6.input_layernorm, model.layers.12.post_attention_layernorm, model.layers.15.self_attn.v_proj, model.layers.0.self_attn, model.layers.7.self_attn, model.layers.0.self_attn.v_proj, model.layers.15.input_layernorm, model.layers.30.self_attn.k_proj, model.rotary_emb, model.layers.5.self_attn.v_proj, model.layers.25, model.layers.5.input_layernorm, model.layers.28.post_attention_layernorm, model.norm, model.layers.9.mlp.down_proj, model.layers.13.mlp.down_proj, model.layers.20.mlp.up_proj, model.layers.7.self_attn.k_proj, model.layers.8.mlp.down_proj, model.layers.20.mlp.gate_proj, model.layers.0.self_attn.q_proj, model.layers.10.self_attn.o_proj, model.layers.15.self_attn.k_proj, model.layers.5.mlp.act_fn, model.layers.7.mlp.gate_proj, model.layers.17.self_attn.o_proj, model.layers.4.self_attn.q_proj, model.layers.21.self_attn, model.layers.29.self_attn.q_proj, model.layers.5.mlp, model.layers.9.self_attn.q_proj, model.layers.20.self_attn.o_proj, model.layers.24.self_attn.q_proj, model.layers.17.mlp.down_proj, model.layers.15.mlp, model.layers.27.mlp.up_proj, model.layers.0.mlp.act_fn, model.layers.9.mlp.act_fn, model.layers.4.post_attention_layernorm, model.layers.19.self_attn.o_proj, model.layers.7.mlp.up_proj, model.layers.23.mlp, model.layers.13.mlp.gate_proj, model.layers.25.mlp, model.layers.14.mlp.up_proj, model.layers.1.mlp.act_fn, model.layers.15.self_attn.o_proj, model.layers.13.input_layernorm, model.layers.19.mlp.gate_proj, model.layers.23.self_attn.k_proj, model.layers.11.self_attn.o_proj, model.layers.1.mlp, model.layers.17.self_attn.q_proj, model.layers.12.self_attn.v_proj, model.layers.12.input_layernorm, model.layers.1, model.layers.19.input_layernorm, model.layers.4.input_layernorm, model.layers.25.mlp.down_proj, model.layers.14.self_attn.k_proj, model.layers.9.post_attention_layernorm, model.layers.0.mlp.down_proj, model.layers.17.input_layernorm, model.layers.11.mlp.act_fn, model.layers.13.self_attn.k_proj, model.layers.31.mlp.down_proj, model.layers.8.input_layernorm, model.layers.2.mlp.up_proj, model.layers.8.mlp, model.layers.18.mlp, model.layers.3.self_attn.k_proj, model.layers.28.self_attn.q_proj, model.layers.13, model.layers.18.post_attention_layernorm, model.layers.28.input_layernorm, model.layers.29.mlp.up_proj, model.layers.26.mlp, model.layers.28.self_attn.v_proj, model.layers, model.layers.22.mlp.down_proj, model.layers.29.mlp.down_proj, model.layers.4, model.layers.31.input_layernorm, model.layers.9.self_attn.o_proj, model.layers.24.mlp, model.layers.27.self_attn.q_proj, model.layers.13.mlp.up_proj, model.layers.1.mlp.gate_proj, model.layers.13.self_attn.o_proj, model.layers.31.self_attn.q_proj, model.layers.2.self_attn.k_proj, model.layers.18.self_attn.k_proj, model.layers.16.mlp, model.layers.30.mlp.up_proj, model.layers.12.mlp.act_fn, model.layers.25.mlp.act_fn, model.layers.31.mlp.gate_proj, model.layers.30.self_attn, model.layers.4.self_attn.k_proj, model.layers.7.self_attn.q_proj, model.layers.6.post_attention_layernorm, model.layers.28.self_attn.o_proj, model.layers.17.self_attn.v_proj, model.layers.5.mlp.down_proj, model.layers.2.mlp, model.layers.22.self_attn.o_proj, model.layers.7.mlp.down_proj, model.layers.18.self_attn.o_proj, model.layers.2.self_attn, model.layers.19.mlp.down_proj, model.layers.13.mlp, model.layers.3.self_attn.v_proj, model.layers.23.mlp.act_fn, model.embed_tokens, model.layers.5.post_attention_layernorm, model.layers.19.self_attn, model.layers.17.mlp, model.layers.25.self_attn, model.layers.29.self_attn.v_proj, model.layers.24.self_attn.o_proj, model.layers.31.self_attn.o_proj, model.layers.9.self_attn, model.layers.5.mlp.up_proj, model.layers.16.self_attn.q_proj, model.layers.0.post_attention_layernorm, model.layers.29.mlp.act_fn, model.layers.14.self_attn.q_proj, model.layers.30.mlp.gate_proj, model.layers.14.mlp.gate_proj, model.layers.2.input_layernorm, model.layers.28.self_attn.k_proj, model.layers.20.mlp.act_fn, model.layers.12.mlp.down_proj, model.layers.17, model.layers.29, model.layers.0.self_attn.o_proj, model.layers.17.mlp.gate_proj, model.layers.27.post_attention_layernorm, model.layers.16.mlp.gate_proj, model.layers.9.self_attn.k_proj, model.layers.18.input_layernorm, model.layers.20.post_attention_layernorm, model.layers.4.mlp.up_proj, model.layers.23.mlp.gate_proj, model.layers.6.mlp, model.layers.26.self_attn.v_proj, model.layers.8.mlp.gate_proj, model.layers.2.self_attn.v_proj, model.layers.8.post_attention_layernorm, model.layers.16.self_attn.o_proj, model.layers.4.mlp.down_proj, model.layers.5.self_attn.q_proj, model.layers.27.mlp.act_fn, model.layers.10, model.layers.17.mlp.up_proj, model.layers.9.self_attn.v_proj, model.layers.28.mlp.gate_proj, model.layers.8.self_attn.o_proj, model.layers.24.self_attn.k_proj, model.layers.22.self_attn.k_proj, model.layers.8.self_attn.k_proj, model.layers.26.self_attn, model.layers.7.self_attn.v_proj, model.layers.20.self_attn.k_proj, model.layers.25.post_attention_layernorm, model.layers.10.self_attn.q_proj, model.layers.0.mlp.up_proj, model.layers.21.mlp.act_fn, model.layers.15.mlp.act_fn, model.layers.6, model.layers.12.self_attn.o_proj, model.layers.14.post_attention_layernorm, model.layers.2.self_attn.q_proj, model.layers.4.mlp.act_fn, model.layers.11.mlp, model.layers.16.self_attn.v_proj, model.layers.14.self_attn.v_proj, model.layers.26.mlp.gate_proj, model.layers.6.self_attn.k_proj, model.layers.21.post_attention_layernorm, model.layers.27.self_attn.k_proj, model.layers.6.self_attn, model.layers.25.mlp.gate_proj, model.layers.11, model.layers.20.input_layernorm, model.layers.23.mlp.down_proj, model.layers.8, model.layers.8.self_attn.v_proj, model.layers.8.mlp.act_fn
No layers Skipped.
Model wrapped with FlashDP.
FlashDP requires compilation for the first few iterations, which may take a while. Skipping the first few iterations if you want to compare the performance.
Epoch 1, Loss: 8.8878
Epoch 2, Loss: 7.5151
Epoch 3, Loss: 6.8541
DP Training completed with noise_multiplier=1.0, C=1.0, epochs=3, batch_size=4
Validation Loss: 1.2836
Validation Exact Match Accuracy: 0.3500
Q: Which NFL team represented the AFC at Super Bowl 50?
True: denver broncos
Pred: denver broncos

Q: Which NFL team represented the NFC at Super Bowl 50?
True: carolina panthers
Pred: carolina panthers

Q: Where did Super Bowl 50 take place?
True: santa clara, california
Pred: santa clara, california

Wrapping the model with FlashDP...
Warning: Module type 'LayerNorm' specified in target_modules is not used in the model.
Layers Wrapped: model.layers.0.mlp, model.layers.18.self_attn.q_proj, model.layers.16.mlp.down_proj, model.layers.19.mlp.up_proj, model.layers.1.mlp.down_proj, model.layers.13.mlp.act_fn, model.layers.14.mlp.act_fn, model.layers.0.self_attn.k_proj, model.layers.15.post_attention_layernorm, model.layers.5.self_attn.k_proj, model.layers.19.self_attn.q_proj, model.layers.21.mlp.up_proj, model.layers.18.mlp.act_fn, model.layers.7.mlp.act_fn, model.layers.3.mlp.up_proj, model.layers.7.input_layernorm, model.layers.26.self_attn.k_proj, model.layers.22.mlp.up_proj, model.layers.18.self_attn, model.layers.6.mlp.down_proj, model.layers.22.self_attn.v_proj, model.layers.5.mlp.gate_proj, model.layers.16.input_layernorm, model.layers.0.mlp.gate_proj, model.layers.31.mlp.act_fn, model.layers.24.mlp.gate_proj, model.layers.3, model.layers.3.mlp.gate_proj, model.layers.26.post_attention_layernorm, model.layers.19.self_attn.k_proj, model.layers.27.self_attn.v_proj, model.layers.11.post_attention_layernorm, model.layers.24.self_attn, model.layers.25.input_layernorm, model.layers.25.self_attn.q_proj, model.layers.24.mlp.act_fn, model.layers.5.self_attn.o_proj, model.layers.3.input_layernorm, model.layers.9.mlp.up_proj, model.layers.27.self_attn, model.layers.4.mlp, model.layers.20.self_attn.q_proj, model.layers.1.mlp.up_proj, model.layers.12, model.layers.23.post_attention_layernorm, model.layers.3.mlp, model.layers.28.mlp.up_proj, model.layers.12.mlp.up_proj, model.layers.21.self_attn.k_proj, model.layers.26.self_attn.o_proj, model.layers.18, model.layers.27.mlp.gate_proj, model.layers.14.self_attn, model.layers.27.mlp.down_proj, model.layers.9.mlp.gate_proj, model.layers.1.self_attn, model.layers.29.self_attn, model.layers.22, model.layers.3.self_attn.q_proj, model.layers.24.input_layernorm, model.layers.27.self_attn.o_proj, model.layers.16, model.layers.19.mlp.act_fn, model.layers.31.mlp, model.layers.30.input_layernorm, model.layers.22.mlp, model.layers.23.self_attn.q_proj, model.layers.24, model.layers.30.mlp.down_proj, model.layers.14.input_layernorm, model.layers.28, model.layers.15.self_attn, model.layers.17.self_attn, model.layers.26.input_layernorm, model.layers.10.mlp.gate_proj, model.layers.30.self_attn.v_proj, model.layers.16.self_attn, model.layers.21.self_attn.o_proj, model.layers.12.self_attn.k_proj, model.layers.26.mlp.up_proj, model.layers.12.mlp.gate_proj, model.layers.10.mlp.up_proj, model.layers.10.mlp.act_fn, model.layers.6.mlp.up_proj, model.layers.19.post_attention_layernorm, model.layers.30.self_attn.o_proj, model.layers.1.self_attn.v_proj, model.layers.30.self_attn.q_proj, model.layers.7.post_attention_layernorm, model.layers.29.mlp.gate_proj, model.layers.21.mlp, model.layers.19.mlp, model.layers.14.self_attn.o_proj, model.layers.2.post_attention_layernorm, model.layers.9.mlp, model.layers.25.self_attn.o_proj, model.layers.21.input_layernorm, model.layers.22.self_attn.q_proj, model.layers.29.self_attn.o_proj, model.layers.19.self_attn.v_proj, model.layers.22.self_attn, model.layers.20.self_attn.v_proj, model.layers.20.mlp.down_proj, model.layers.19, model.layers.18.self_attn.v_proj, model.layers.5.self_attn, model.layers.3.mlp.down_proj, model.layers.16.mlp.act_fn, model.layers.28.mlp, model.layers.21.mlp.down_proj, model.layers.9, model.layers.18.mlp.gate_proj, model.layers.20.self_attn, model.layers.11.mlp.up_proj, model.layers.23.self_attn.o_proj, model.layers.24.self_attn.v_proj, model.layers.3.self_attn.o_proj, model.layers.8.mlp.up_proj, model.layers.21.mlp.gate_proj, model.layers.30.mlp.act_fn, model.layers.6.self_attn.o_proj, model.layers.2, model.layers.23.mlp.up_proj, model.layers.26.mlp.down_proj, model.layers.14.mlp.down_proj, model.layers.11.mlp.gate_proj, model.layers.1.self_attn.o_proj, model.layers.17.mlp.act_fn, model.layers.10.mlp.down_proj, model.layers.5, model.layers.15.mlp.gate_proj, model.layers.29.mlp, model.layers.22.post_attention_layernorm, model.layers.13.self_attn, model.layers.2.mlp.down_proj, model.layers.1.input_layernorm, model.layers.23.input_layernorm, model.layers.28.mlp.down_proj, model.layers.15.self_attn.q_proj, model.layers.23.self_attn, model.layers.24.post_attention_layernorm, model.layers.10.input_layernorm, model.layers.27.input_layernorm, model.layers.28.mlp.act_fn, model.layers.2.mlp.gate_proj, model.layers.22.input_layernorm, model.layers.8.self_attn.q_proj, model.layers.6.mlp.gate_proj, model.layers.4.mlp.gate_proj, model.layers.2.mlp.act_fn, model.layers.6.self_attn.q_proj, model.layers.18.mlp.down_proj, model.layers.30.post_attention_layernorm, model.layers.6.mlp.act_fn, model.layers.29.self_attn.k_proj, model.layers.23, model.layers.20, model.layers.16.post_attention_layernorm, model.layers.21, model.layers.29.post_attention_layernorm, model.layers.13.self_attn.q_proj, model.layers.26.self_attn.q_proj, model.layers.0.input_layernorm, model.layers.15, lm_head, model.layers.31.mlp.up_proj, model.layers.16.self_attn.k_proj, model.layers.2.self_attn.o_proj, model.layers.14, model.layers.12.self_attn, model.layers.30, model.layers.0, model.layers.11.self_attn.v_proj, model.layers.4.self_attn, model.layers.31.self_attn, model.layers.10.post_attention_layernorm, model.layers.13.self_attn.v_proj, model.layers.26, model.layers.22.mlp.gate_proj, model.layers.15.mlp.up_proj, model.layers.25.self_attn.k_proj, model.layers.11.self_attn.k_proj, model.layers.30.mlp, model.layers.12.self_attn.q_proj, model.layers.13.post_attention_layernorm, model.layers.3.post_attention_layernorm, model.layers.28.self_attn, model.layers.25.self_attn.v_proj, model.layers.4.self_attn.o_proj, model.layers.11.input_layernorm, model.layers.7, model.layers.10.self_attn, model.layers.1.self_attn.k_proj, model.layers.31.self_attn.k_proj, model.layers.31.self_attn.v_proj, model.layers.1.self_attn.q_proj, model.layers.25.mlp.up_proj, model.layers.20.mlp, model.layers.10.self_attn.v_proj, model.layers.7.mlp, model.layers.31, model.layers.26.mlp.act_fn, model.layers.16.mlp.up_proj, model.layers.21.self_attn.q_proj, model.layers.9.input_layernorm, model.layers.11.self_attn.q_proj, model.layers.14.mlp, model.layers.3.self_attn, model.layers.27, model.layers.15.mlp.down_proj, model.layers.22.mlp.act_fn, model.layers.29.input_layernorm, model.layers.31.post_attention_layernorm, model.layers.1.post_attention_layernorm, model.layers.10.self_attn.k_proj, model.layers.8.self_attn, model.layers.11.self_attn, model.layers.11.mlp.down_proj, model.layers.17.self_attn.k_proj, model.layers.10.mlp, model.layers.23.self_attn.v_proj, model.layers.21.self_attn.v_proj, model.layers.24.mlp.down_proj, model, model.layers.3.mlp.act_fn, model.layers.27.mlp, model.layers.24.mlp.up_proj, model.layers.6.self_attn.v_proj, model.layers.4.self_attn.v_proj, model.layers.17.post_attention_layernorm, model.layers.7.self_attn.o_proj, model.layers.18.mlp.up_proj, model.layers.12.mlp, model.layers.6.input_layernorm, model.layers.12.post_attention_layernorm, model.layers.15.self_attn.v_proj, model.layers.0.self_attn, model.layers.7.self_attn, model.layers.0.self_attn.v_proj, model.layers.15.input_layernorm, model.layers.30.self_attn.k_proj, model.rotary_emb, model.layers.5.self_attn.v_proj, model.layers.25, model.layers.5.input_layernorm, model.layers.28.post_attention_layernorm, model.norm, model.layers.9.mlp.down_proj, model.layers.13.mlp.down_proj, model.layers.20.mlp.up_proj, model.layers.7.self_attn.k_proj, model.layers.8.mlp.down_proj, model.layers.20.mlp.gate_proj, model.layers.0.self_attn.q_proj, model.layers.10.self_attn.o_proj, model.layers.15.self_attn.k_proj, model.layers.5.mlp.act_fn, model.layers.7.mlp.gate_proj, model.layers.17.self_attn.o_proj, model.layers.4.self_attn.q_proj, model.layers.21.self_attn, model.layers.29.self_attn.q_proj, model.layers.5.mlp, model.layers.9.self_attn.q_proj, model.layers.20.self_attn.o_proj, model.layers.24.self_attn.q_proj, model.layers.17.mlp.down_proj, model.layers.15.mlp, model.layers.27.mlp.up_proj, model.layers.0.mlp.act_fn, model.layers.9.mlp.act_fn, model.layers.4.post_attention_layernorm, model.layers.19.self_attn.o_proj, model.layers.7.mlp.up_proj, model.layers.23.mlp, model.layers.13.mlp.gate_proj, model.layers.25.mlp, model.layers.14.mlp.up_proj, model.layers.1.mlp.act_fn, model.layers.15.self_attn.o_proj, model.layers.13.input_layernorm, model.layers.19.mlp.gate_proj, model.layers.23.self_attn.k_proj, model.layers.11.self_attn.o_proj, model.layers.1.mlp, model.layers.17.self_attn.q_proj, model.layers.12.self_attn.v_proj, model.layers.12.input_layernorm, model.layers.1, model.layers.19.input_layernorm, model.layers.4.input_layernorm, model.layers.25.mlp.down_proj, model.layers.14.self_attn.k_proj, model.layers.9.post_attention_layernorm, model.layers.0.mlp.down_proj, model.layers.17.input_layernorm, model.layers.11.mlp.act_fn, model.layers.13.self_attn.k_proj, model.layers.31.mlp.down_proj, model.layers.8.input_layernorm, model.layers.2.mlp.up_proj, model.layers.8.mlp, model.layers.18.mlp, model.layers.3.self_attn.k_proj, model.layers.28.self_attn.q_proj, model.layers.13, model.layers.18.post_attention_layernorm, model.layers.28.input_layernorm, model.layers.29.mlp.up_proj, model.layers.26.mlp, model.layers.28.self_attn.v_proj, model.layers, model.layers.22.mlp.down_proj, model.layers.29.mlp.down_proj, model.layers.4, model.layers.31.input_layernorm, model.layers.9.self_attn.o_proj, model.layers.24.mlp, model.layers.27.self_attn.q_proj, model.layers.13.mlp.up_proj, model.layers.1.mlp.gate_proj, model.layers.13.self_attn.o_proj, model.layers.31.self_attn.q_proj, model.layers.2.self_attn.k_proj, model.layers.18.self_attn.k_proj, model.layers.16.mlp, model.layers.30.mlp.up_proj, model.layers.12.mlp.act_fn, model.layers.25.mlp.act_fn, model.layers.31.mlp.gate_proj, model.layers.30.self_attn, model.layers.4.self_attn.k_proj, model.layers.7.self_attn.q_proj, model.layers.6.post_attention_layernorm, model.layers.28.self_attn.o_proj, model.layers.17.self_attn.v_proj, model.layers.5.mlp.down_proj, model.layers.2.mlp, model.layers.22.self_attn.o_proj, model.layers.7.mlp.down_proj, model.layers.18.self_attn.o_proj, model.layers.2.self_attn, model.layers.19.mlp.down_proj, model.layers.13.mlp, model.layers.3.self_attn.v_proj, model.layers.23.mlp.act_fn, model.embed_tokens, model.layers.5.post_attention_layernorm, model.layers.19.self_attn, model.layers.17.mlp, model.layers.25.self_attn, model.layers.29.self_attn.v_proj, model.layers.24.self_attn.o_proj, model.layers.31.self_attn.o_proj, model.layers.9.self_attn, model.layers.5.mlp.up_proj, model.layers.16.self_attn.q_proj, model.layers.0.post_attention_layernorm, model.layers.29.mlp.act_fn, model.layers.14.self_attn.q_proj, model.layers.30.mlp.gate_proj, model.layers.14.mlp.gate_proj, model.layers.2.input_layernorm, model.layers.28.self_attn.k_proj, model.layers.20.mlp.act_fn, model.layers.12.mlp.down_proj, model.layers.17, model.layers.29, model.layers.0.self_attn.o_proj, model.layers.17.mlp.gate_proj, model.layers.27.post_attention_layernorm, model.layers.16.mlp.gate_proj, model.layers.9.self_attn.k_proj, model.layers.18.input_layernorm, model.layers.20.post_attention_layernorm, model.layers.4.mlp.up_proj, model.layers.23.mlp.gate_proj, model.layers.6.mlp, model.layers.26.self_attn.v_proj, model.layers.8.mlp.gate_proj, model.layers.2.self_attn.v_proj, model.layers.8.post_attention_layernorm, model.layers.16.self_attn.o_proj, model.layers.4.mlp.down_proj, model.layers.5.self_attn.q_proj, model.layers.27.mlp.act_fn, model.layers.10, model.layers.17.mlp.up_proj, model.layers.9.self_attn.v_proj, model.layers.28.mlp.gate_proj, model.layers.8.self_attn.o_proj, model.layers.24.self_attn.k_proj, model.layers.22.self_attn.k_proj, model.layers.8.self_attn.k_proj, model.layers.26.self_attn, model.layers.7.self_attn.v_proj, model.layers.20.self_attn.k_proj, model.layers.25.post_attention_layernorm, model.layers.10.self_attn.q_proj, model.layers.0.mlp.up_proj, model.layers.21.mlp.act_fn, model.layers.15.mlp.act_fn, model.layers.6, model.layers.12.self_attn.o_proj, model.layers.14.post_attention_layernorm, model.layers.2.self_attn.q_proj, model.layers.4.mlp.act_fn, model.layers.11.mlp, model.layers.16.self_attn.v_proj, model.layers.14.self_attn.v_proj, model.layers.26.mlp.gate_proj, model.layers.6.self_attn.k_proj, model.layers.21.post_attention_layernorm, model.layers.27.self_attn.k_proj, model.layers.6.self_attn, model.layers.25.mlp.gate_proj, model.layers.11, model.layers.20.input_layernorm, model.layers.23.mlp.down_proj, model.layers.8, model.layers.8.self_attn.v_proj, model.layers.8.mlp.act_fn
No layers Skipped.
Model wrapped with FlashDP.
FlashDP requires compilation for the first few iterations, which may take a while. Skipping the first few iterations if you want to compare the performance.
Epoch 1, Loss: 8.9720
Epoch 2, Loss: 7.5297
Epoch 3, Loss: 6.8892
DP Training completed with noise_multiplier=1.0, C=1.0, epochs=3, batch_size=4
Validation Loss: 1.2912
Validation Exact Match Accuracy: 0.3300
Q: Which NFL team represented the AFC at Super Bowl 50?
True: denver broncos
Pred: denver broncos

Q: Which NFL team represented the NFC at Super Bowl 50?
True: carolina panthers
Pred: carolina panthers

Q: Where did Super Bowl 50 take place?
True: santa clara, california
Pred: santa clara, california

